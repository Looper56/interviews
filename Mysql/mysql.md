### Mysql Basics

#### Mysql架构
 mysql架构可以在多种不同场景作用，主要体现在存储引擎架构上，`插件式存储引擎架构将查询处理和其他的系统任务以及数据的存储提取相分离`，根据业务选择
 - 连接层：最上层是一些客户端和连接服务，主要完成类似连接处理，授权认证，相关安全方案，基于SSL安全链接
 - 服务层：核心服务功能，包括查询解析、分析、优化、缓存及内置函数，跨存储引擎包括触发器、存储过程、视图等
 - 引擎层：存储引擎真正负责mysql中数据的存储和提取，服务器通过API与存储引擎进行通信
 - 存储层：主要将数据存储在运行于该设备的文件系统上，并完成与存储引擎的交互
##### Mysql查询流程
 客户端请求 -> 连接器(验证用户身份，给予权限) -> 查询缓存(有则返回) -> 分析器(对SQL词法语法分析) -> 优化器(对执行sql选择最佳执行方案) -> 执行器(先看用户权限，使用引擎接口) -> 引擎层获取数据返回(开启缓存则缓存查询结果)

#### Mysql引擎
 常见存储引擎：InnoDB、MyISAM、Memory、NDB
 InnoDB是Mysql默认存储引擎，支持事务、行级锁定和外键
 MyISAM物理文件结构：
 - .frm：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息
 - .MYD：存储表数据
 - .MYI：存储表索引相关信息
 InnoDB物理文件结构：
 - .frm：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息
 - .ibd/.ibdata：都是存放InnoDB数据的文件，因为InnoDB的数据存储方式通过配置来决定`共享表空间`还是`独享表空间`
 InnoDB和MyISAM引擎区别：
 - InnoDB支持事务，成为mysql默认引擎重要原因之一
 - InnoDB支持外键，包含外键的转表会失败
 - InnoDB是聚簇索引，因此必须要有主键，聚簇索引文件存放在主键索引的叶子节点上，通过主键索引效率高，但是辅助索引需要两次查询，先查询主键，再通过主键查询数据，主键不宜过大，导致其他索引过大
 - InnoDB不保存表的具体行数，执行`select count(*)...`扫描全表，MyISAM用变量保存整表行数
 - InnoDB最小的锁粒度是行锁，MyISAM最小的锁粒度是表锁，更新语句会锁柱整张表，导致阻塞
 `一张表，里面有ID自增主键，当insert了17条记录之后，删除第15，16，17条记录，重启Mysql，再insert，该ID为`
 - MyISAM类型：18，MyISAM会把自增最大ID记录到数据文件中，重启不会丢失
 - InnoDB类型：15，InnoDB只是把最大ID记录到内存中，重启会对表进行OPTION操作，导致丢失

#### Mysql数据类型
 `CHAR和VARCHAR区别`
 - char是固定长度，varchar长度可变
 - char按规定长度分配存储空间，varchar根据实际分配空间
 - 相同点：超过最大长度限制后，字符串会被截断
 - 不同点：char存储上限为255字节，char存储时会截断尾部空格
 char适合存储很短、长度固定的字符串，例如MD5值
 `列的字符串类型可以是什么`
 - 字符串类型是：SET BLOB ENUM CHAR TEXT VARCHAR
 `BLOB和TEXT区别`
 - BLOB是二进制对象，可容纳可变数量数据，四种类型：BLOB TINYBLOB BLOB MEDIUMBLOB LONGBLOB
 - TEXT是一个不区分大小写的BLOB，四种类型：TINYTEXT TEXT MEDIUMTEXT LONGTEXT
 BLOB保存二进制数据，TEXT保存字符串数据

#### Mysql索引
  [索引参考](https://www.cnblogs.com/kungfupanda/p/12776674.html)
 索引(index)是帮助Mysql高效获取数据的`数据结构`
 简单理解为`排好序快速查找的数据结构`，数据本身之外，数据库还维护一个满足特定查找算法的数据结构
 索引本身也很大，不可能全部存储在内存中，一般以索引文件形式存储在磁盘上
 平常默认索引就是B+树(多路搜索树，不一定是二叉树)结构组织的索引，其中：聚集索引、次要索引，覆盖索引，复合索引、前缀索引，唯一索引默认都是使用B+树索引，此外还有哈希索引等
 优势：
 - 提高数据检索效率，降低数据库IO成本
 - 降低数据排序成本，降低CPU消耗
 劣势：
 - 索引也是一张表，保存主键和索引字段，并指向实体表的记录，所以也需要内存
 - 降低更新表的速度，更新时不仅保存数据，还要保存索引文件每次更新索引字段
 索引分类
 ##### 数据结构角度：
 - B+树索引
 - Hash索引
 - Full-Text全文索引
 - R-tree索引(空间索引)
 ##### 物理存储角度：
 - 聚簇索引
 - 非聚簇索引(辅助索引)
   都是B+树结构
 ##### 逻辑角度：
 - 主键索引：特殊的唯一索引，不允许有空值
 - 普通索引或单列索引：每个索引只包含单个列，一个表可以多个单列索引
 - 多列索引(复合索引、联合索引)：多个字段创建的索引，查询中使用创建索引的第一个字段，索引才会被使用，最左原则
 - 唯一索引或非唯一索引
 - 空间索引：是对空间数据类型字段建立的索引：GEOMETRY POINT LINESTRING POLYGON
   Mysql必须使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引，空间索引列需声明为NOT NULL
   空间索引只能在存储引擎为MYISAM表创建
  索引实在存储引擎层面实现的，并不是所有存储引擎都支持所有的索引类型，实现和行为有差异
  ##### B+树和B树的区别
  - B+树非叶子节点只包含导航信息，不包含实际的值，所有的叶子节点和相连的节点都使用链表相连，便于区间查找和遍历
  B+树优点在于
  - IO次数更少：内部节点上不包含数据信息，因此能够存放更多的key，数据存放更加紧密，更好的空间局部性，访问叶子关联数据也有更好的缓存命中率
  - 遍历更加方便：B+树的叶子节点都是相连的，因此整棵树只需要一次线性遍历即可，便于区间查找和搜索
  B树优点
  - 每个节点包含key和value，经常访问的元素可能离根节点更近，更迅速
   `为什么Mysql索引中用B+树，不用B树，为什么不用Hash索引`
  - B+树磁盘读写代价更低：B+树内部节点没有关键字具体信息指针，因此内部节点相对B树更小，读入内存的需要查找的关键字也就多，相对IO读写次数降低
  - B+树的查询效率更加稳定：由于非终结点并不是最终指向文件内容的节点，而只是叶子节点的关键字索引，关键字查询路径长度相同，数据查询效率相当
  - B+树更便于遍历：B+树数据都存储在叶子节点，分支节点为索引，方便扫库，B树节点存储着数据，需遍历按序来扫
  - B+树更适合基于范围的查询：B树再提高IO性能的同时并没有解决元素遍历的效率低下的问题，B+只需要遍历叶子节点就可以实现遍历整棵树的遍历，而且再数据库中基于范围查询是非常频繁的
##### MyISAM主键索引与辅助索引的结构
 MyISAM引擎的索引文件和数据文件是分离的，`MyISAM引擎索引结构的叶子节点的数据域，存放的并不是实际数据，而是数据地址`
 索引文件和数据文件分离，索引称为`非聚簇索引`
##### InnoDB主键索引与辅助索引的结构
 `InnoDB引擎索引结构的叶子节点的数据域，存放的就是实际数据记录`，或说InnoDB数据文件本身就是主键索引文件，称为`聚簇索引`
##### 主键索引
 InnoDB索引和数据存入同一个.ibd文件中，因此它的索引结构是在同一个树节点中同时存放索引和数据
 在InnoDB中，索引分叶子节点和非叶子节点，非叶子节点如目录，单独存放在索引段，叶子节点则是按顺序排序，在数据段中，数据文件可以按照表切分(开启innodb_file_per_table)，切分后存放在xxx.ibd，默认不切分存放在xxx.ibdata
##### 辅助(非主键)索引
 辅助索引与主键索引差别在最底层叶子节点数据行，辅助索引按照ASCII码进行排序
 意味着对字段进行条件搜索需要步骤
 - 在辅助索引上检索字段，到达其叶子节点获取对应的主键
 - 使用主键在主索引上再进行对应的检索操作
 这就是所谓的`回表查询`
##### InnoDB索引结构需要注意的点
 - 数据文件本身就是索引文件
 - 表数据文件本身就是按B+树组织的一个索引结构文件
 - 聚簇索引中叶子节点包含了完整的数据记录
 - InnoDB表必须要有主键，并且推荐使用整型自增主键
 索引与数据是共同存储的，不管主键索引还是辅助索引，在查找时都是通过先查找到索引节点才能拿到对应数据，如果我们在设计表结构时没有`显式指定索引列`的话，Mysql会从表中选择数据不重复的列建立索引，如果没有符合的列，则Mysql自动为InnoDB生成一个隐含字段作为主键，并且长度为6个字节，类型为整型
##### 为什么推荐使用整型自增主键而不是选择UUID
 - UUID是字符串，比整型消耗更多存储空间
 - 在B+树中进行查找时需要跟经过的节点值比较大小，整型数据的比较运算比字符串更快
 - 自增的整型索引在磁盘中会连续存储，在读取一页的数据时也是连续，UUID是随机产生的。读取上下的数据存储是分散的，不适合范围查询
 - 在插入或删除数据时，整型自增主键会在叶子节点的末尾建立新的叶子节点，`不会破坏左侧子树的结构`，UUID容易出现这种情况，B+树为了维持自身特性，有可能进行结构重构，消耗更多时间
##### Hash索引
 - 主要通过Hash算法(直接定址法、平方取中法、折叠法、除数取余法、随机数法)，将数据库字段转换为定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置，如果发生Hash碰撞，则在对应Hash键下以链表形式存储
 - 检索算法：在检索查询时，就再次对待查关键字执行相同的Hash算法，得到Hash值，到对应Hash表对应位置去除数据，如果发生碰撞则需要在取值时进行筛选
###### 为什么不用Hash作为索引
 - 区间值难找，因为单个值计算很快，需遍历全部Hash节点
 - 排序难，压缩算法，大小值可能落在一个Hash桶里，容易产生Hash冲突 
##### FULL-TEXT全文索引
 - 全文索引也是MyISAM的一种特殊索引类型，InnoDB从5.6支持
 - 它用于替代效率较低的LIKE模糊匹配查询，而且可以通过多个字段组合的全文索引一次性全模糊匹配多个字段
 - 同样使用B树存放索引，但使用特定算法，将字段数据分割后再进行索引(4个字节分割一次)
##### 需创建索引的情况
 - 主键自动建立唯一索引
 - 频繁作为查询条件的字段
 - 查询中与其他表关联的字段，外键关系建立索引
 - 单键/组合索引的选择问题，高并发下倾向创建组合索引
 - 查询中排序的字段，排序字段通过索引访问大幅度提高排序速度
 - 查询中统计或分组字段
##### 不需创建索引情况
 - 表记录太少
 - 经常增删改查
 - 数据重复且分布均匀表字段
 - 频繁更新的字段(加重IO负担)
 - where条件用不到的字段
##### Mysql高效索引
 覆盖索引(covering index)，不需要回表操作
 - 就是select的数据列只用从索引中就能得到，不必读取行数据，`查询列要被所建索引覆盖`
 - 索引高效找到行的一个方法，一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行，当能通过读取索引就能得到想要的数据，一个索引包含(覆盖)满足查询结果的数据就是覆盖索引
 - 判断标准：使用explain，通过extra列判断，对于覆盖索引查询显示`using index`，Mysql查询优化器在执行查询前会决定是否有覆盖查询

#### Mysql查询
 `count(*) count(1) count(filed) 区别`
 - 执行效果
   - count(*)包括所有列，相当于行数，在统计结果时候，不会忽略列值为NULL
   - count(1)包括所有列，用1代表代码行，在统计结果时候，不会忽略列值为NULL
   - count(filed)，只包括那一列，会忽略列值为空的计数
 - 执行效率
   - filed为主键，count(filed) > count(1)
   - filed不为主键，count(1) > count(filed)
   - 如果表多个列并且没有主键，则count(1) > count(*)
   - 如果有主键,count(filed)最优
   - 如果表只有一个字段 count(*)最优
 `Mysql中in和exists的区别`
  - exists：exists对外表用loop逐条查询，每次查询都会查看exists的条件语句，当exits里的条件语句能够返回记录行时，条件就为真，返回当前loop到这条记录，exists的条件就像一个bool条件，当能够返回结果集为true，不能返回结果集为false
  - in：in查询相对与多个or条件的叠加
  如果查询的两个表大小相当，那么用in和exists差别不大
  一个是大表，则子查询用exists，小表子查询用in
  `UNION和UNION ALL的区别`
  都是将两个结果集合并为一个，两个要联合的sql语句 字段个数必须一样，而且字段类型要一致
  - UNION再进行表连接后会筛选掉重复的数据记录(效率较低)，而UNION ALL则不会去掉重复的数据记录
  - UNION会按照字段的顺序进行排序，而UNION ALL只是简单的将两个结果合并返回

#### Mysql事务
##### ACID-事务基本要素
 - Atomicity原子性：整个事务的所有操作，要么全部完成，要么全部不完成，发生错误回滚到事务之前状态
 - Consistency一致性：在事务开始和结束后，数据库的完整性约束没有被破坏
 - Isolation隔离性：事务之间互不干扰，事务内部操作及使用数据对其他并发事务是隔离的
 - Durability持久性：在事务完成之后，该事务所对数据库的所做更改便持久保存在数据库中
##### 并发事务处理带来的问题
 - 更新丢失(Lost Update)：事务AB选择同一行，然后基于最初选定的值更新该行，由于两个事务彼此不知，发生丢失更新
 - 脏读(Dirty Reads)：事务A读取事务B更新的数据，然后事务B回滚操作，那么事务A读取的就是脏数据
 - 不可重复读(Non-Repeatable Reads)：事务A多次读取同一数据，事务B在事务A多次读取的过程更新提交，导致多次读取不一致
 - 幻读(Phantom Reads)：类似不可重复读，在事务A读取时，事务B插入数据，在随后查询中，事务A发现不存在的记录
 幻读和不可重复读的区别：
 不可重复读重点是`修改`，幻读重点在于`新增或删除` 
##### 并发事务处理带来的问题及解决方案
 - 更新丢失：通常应该完全避免的，防止更新丢失并不能单靠数据库事务控制器解决，需要应用程序对更新数据`加锁`，应是应用责任
 - 脏读、不可重复读、幻读：都是数据库一致性问题，必须由数据库提供一定的事务隔离机制解决
   - 加锁：在读取数据前加锁，阻止其他事务对数据进行修改
   - 数据多版本并发控制(MultiVersion Concurrency Control 简称MVCC或MCC)，不用加任何锁，通过一定机制生成一个数据请求时间点的一致性数据快照(Snapshot)，并用快照提供一定级别的一致性读取，用户角度来看，是数据库可以提供一个数据多个版本
##### 事务隔离级别
 事务隔离级别由低到高
 - 读未提交：最低隔离级别，允许读取尚未提交的数据变更，可能导致`脏读、幻读、不可重复读`
 - 读已提交：允许读取并发事务已提交的数据，可阻止脏读，可导致`幻读、不可重复读`
 - 可重复读(默认)：对同一字段多次读取结果都是一致的，除非数据都是被本身事务自己修改，可阻止脏读和不可重读夫，可导致`幻读`
 - 可串行化：最高隔离级别，完全服从ACID，所有事务逐个执行，事务之间不产生干扰
 查看事务隔离级别：`show variables like 'tx_isolation'`
 事务隔离越严格，并发副作用越小，代价越大，串行化与并发矛盾，根据应用决定，对于不敏感更关系并发访问能力
##### MVCC多版本并发控制
 Mysql大多数事务型存储引擎都不是简单行级锁，基于提升并发性考虑，各实现机制不同
 MVCC是行级锁的一个变种，很多情况避免加锁的操作，因此开销更低，大都实现非阻塞读操作，写操作也只是锁定必要行
 MVCC实现都是通过某个时间点的快照实现，每个事务看到的数据是一致
 典型的MVCC实现方式：分为 `乐观并发控制` `悲观并发控制`
 可重复读隔离级别下MVCC工作方式：
 - SELECT
   - InnoDB根据以下条件检查每行记录：
      - 只查找版本早于当前事务版本的数据行，保证事务读取的行是在事务开始之前存在或是事务自身修改过的
      - 行删除的版本号要么未定义，要么大于当前事务版本号，保证事务读取到的行在事务开始之前未被删除
      只有符合条件才会被查询
 - INSERT：InnoDB为新插入的每一行保存当前版本号
 - DELETE：InnoDB为删除的每一行保存当前版本号
 - UPDATE：InnoDB为插入的一行新纪录保存当前版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识
##### 事务日志
 InnoDB使用日志来减少提交事务时的开销，日志记录事务，则无须在每个事务提交时把缓冲池的脏块刷新`flush`到磁盘
 事务修改的数据和索引通常会映射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机IO
 随机IO比顺序IO昂贵，因为IO请求需要时间把磁头移到正确位置，待磁盘读出需要的部分，再转到开始位置
 日志把随机IO变成顺序IO，一旦日志安全写到磁盘，事务就持久化，即使断电也能重放日志并恢复已提交的事务
 事务日志帮助提高事务效率：
 - 使用日志时，在修改表时只需要修改其内存拷贝，再把该行为记录到持久在日志，不用每次都将修改持久到磁盘
 - 日志采用的时追加方式，写日志的操作是磁盘上一小块区域内的顺序IO，而不是随机IO需要多处移动磁头
 - 日志持久后，内存中被修改的数据在后台可以慢慢刷回到磁盘
 - 如果数据修改已经记录到日志并持久化，但数据未写入磁盘，系统崩溃重启后能够恢复一部分数据
 统称为`预写式日志(Write-Ahead Logging)`，修改需要写两次磁盘
##### 事务的实现
 事务的实现基于不同的存储引擎(InnoDB和NDB)
 事务的实现就是如何实现ACID特性
 事务的隔离性通过锁实现，而事务原子性、一致性和持久性则是通过事务日志实现
 `事务如何通过日志来实现`
 事务日志包括：`重做日志redo和回滚日志undo`
 - redo log (重做日志) 实现持久化和原子性
   在InnoDB存储引擎中，事务日志通过redo日志和存储引擎日志缓冲(InnoDB Log Buffer)实现
   事务开启时，事务操作会写入存储引擎日志缓冲中，事务提交前缓冲的日志需要提前刷新到磁盘上持久化，`日志先行`
   事务提交后，在Buffer Pool中映射的数据文件才会慢慢刷新到磁盘，数据库发生宕机，重启后根据redo log恢复至崩溃前
   在系统启动时，会为redo log分配一块连续的存储空间，顺序追加的方式记录redo log，通过顺序IO改善性能，事务共享redo log存储空间，redo log按语句执行顺序，依次交替记录
 - undo log (回滚日志) 实现一致性
   undo log主要是为事务的回滚服务，在事务执行过程中也会记录undo log，记录每个操作前的状态，后续可根据undo log回滚事务
   undo记录的是已部分完成并写入磁盘未完成的事务
 两种日志可视为一种恢复操作，redo log是恢复提交事务修改的页操作，是物理日志，记录页的物理修改操作
 undo log是回滚记录到特定版本是逻辑日志，根据每行记录进行记录
##### Mysql有多少种日志
 - 错误日志：记录出错、警告或正确的信息
 - 查询日志：记录所有对数据库的请求信息，不论请求是否得到正确执行
 - 慢查询日志：设置一个阈值，将运行时间超过该值的SQL语句记录到慢查询日志文件中
 - 二进制日志：记录对数据库执行更改的操作
 - 中继日志：也是二进制日志，用来给slave库恢复
 - 事务日志：重做日志redo和回滚日志undo
##### Mysql对分布式事务的支持
 分布式事务实现方式很多，即可采用InnoDB提供的原生事务支持，也可通过消息队列来实现分布式事务的最终一致性
 在Mysql中，分布式事务涉及一个或多个资源管理器和一个事务管理器
 分布式事务模型：应用程序(AP)、资源管理器(RM)、事务管理器(TM)
 - 应用程序：定义事务边界，指定需要做哪些事务
 - 资源管理器：提供访问事务的方法，通常一个数据库就一个资源管理器
 - 事务管理器：协调参与全局事务的各个事务
 分布式事务采用两段式提交(two-phase commit)方式
 - 第一阶段所有事务节点开始准备，告诉事务管理器ready
 - 第二阶段事务管理器告诉每个节点是commit还是rollback，如果一个节点失败，就需要全部节点rollback，保证原子性

#### Mysql锁机制
##### 锁的分类
 数据库操作类型分类
 - 读锁(共享锁 行锁)：针对同一份数据，多个读操作都可以同时进行，互不影响
 - 写锁(排他锁 行锁)：当前写操作没完成前，它会阻断其他读写锁
 数据库操作粒度分类
 - 表级锁：开销小，加锁快，不会出现死锁，锁定粒度大，发生锁冲撞概率大，并发最低 (MyISAM和MEMORY采取表级锁)
 - 行级锁：开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲撞概率低，并发度高 (InnoDB支持行级、表级锁，默认行级锁)
 - 页面锁：开销和时间介于表锁和行锁之间，会出现死锁，粒度介于表级和行级之间，并发一般
 适用：表级锁更适用于以查询为主，只有少量按索引条件更新的应用；行级锁更适合大量索引条件并发更新少量不同数据，又有并发查询
##### MyISAM表锁
 - 表共享读锁：不会阻塞其他用户对同一表的读请求，会阻塞写请求
 - 表独占写锁：会阻塞其他用户对一表的读和写操作
 MyISAM表的读操作与写操作之间，以及写操作之间是串行的，当一个线程获得对一个表的写锁后，只有持有锁的线程才可以对表进行更新操作，其他线程的读写操作都会等待，直至锁被释放
 默认情况，写锁比读锁具有更高的优先级，当一个锁释放时，这个锁优先给写锁队列中等待的获取锁请求，再给读锁队列获取锁请求
##### InnoDB意向锁(Intention Locks)
 - 意向共享锁(IS)：事务打算给数据行加行共享锁，事务在给数据行加锁前必须获得该表的IS锁
 - 意向排他锁(IX)：事务打算给数据行加行排他锁，事务在给数据行加锁前必须获得该表的IX锁
 `索引失效会导致行级锁变表锁，比如varchar查询不单写括号的情况`
##### 加锁机制
 乐观锁和悲观锁是两种并发控制思想，可解决丢失更新问题
 - 乐观锁：假定大概率不会发生并发更新冲突，不加锁，在更新数据时根据版本号或时间戳判断是否冲突，无则提交，有则处理
 - 悲观锁：假定大概率发生更新冲突，数据处理前加排他锁，事务提交后才释放锁，`悲观锁由数据库自己实现，通过相关语句调用`
##### 锁模式
 - 记录锁(Record Locks)：单个记录上的锁，对索引项加锁，锁定符合条件的行，其他事务不能修改和删除加锁项
 `SELECT * FROM TABLE WHERE id = 1 FOR UPDATE;`
 会在id=1的记录加上记录锁，防止其他事务插入，更新、删除该行
 `UPDATE SET age = XX WHERE id = 1;`
 修改也会对该行进行加记录锁
 - 间隙锁(Gap Locks)：当使用范围条件检索数据时，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录索引项加锁
 对索引项之间的`间隙`加锁，锁定记录范围，其他事务不能再所范围内插入数据，防止别的事务新增幻影行
 间隙锁基于非唯一索引，它锁定一段范围内的索引记录，间隙锁基于`Next-Key Locking算法`，锁住的是一个区间，不仅仅每条数据
 `SELECT * FROM TABLE WHERE id BETWEN 1 AND 10 FOR UPDATE;`
 及所有在(1,10)区间的记录都会被锁住，id为2..9的数据行插入会被阻塞，1和10并不会被锁住
 GAP锁的目的，为了防止同一事务的两次当前读，出现幻读的情况
 - 临键锁(Next-key Locks)：是记录锁和间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间
 目的避免幻读，如果事务隔离级别为RC，则临键锁也会失效
 Next-key是一种特殊的间隙锁，特殊的算法，每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁柱左开右闭区间数据，InnoDB中行级锁是基于索引实现的，临键锁只与非唯一索引有关，唯一索引不存在临键锁
 对于行查询，都是采用该方法，目的解决幻读
 `SELECT FOR UPDATE含义`
 for update仅适用于InnoDB，并且必须在事务BEGIN/COMMIT中才能生效，在进行事务操作时通过for update，Mysql会对查询结果集每行数据都添加排他锁，其他线程对该记录的更新等操作会被阻塞
 InnoDB行锁实现意味着，只有通过索引条件检索数据，InnoDB才会使用行级锁，否则InnoDB将使用表锁
 `SELECT * FROM TABLE WHERE id = '1' FOR UPDATE` 明确指定主键，并有此数据，row lock 
 `SELECT * FROM TABLE WHERE id = '-1' FOR UPDATE` 明确指定主键，若无此数据，无 lock 
 `SELECT * FROM TABLE WHERE filed = 'sth' FOR UPDATE` 无主键，table lock 
 `SELECT * FROM TABLE WHERE id <> '1' FOR UPDATE` 主键不明确，table lock 
 `SELECT * FROM TABLE WHERE id LIKE '1' FOR UPDATE` 主键不明确，table lock 
 FOR UPDATE仅适用于InnoDB，且必须在交易区块(BEGIN/COMMIT)，测试锁定可利用Mysql的Command Mode
##### 死锁
 死锁的产生
 - 两个或以上事务在同一资源上相互占用，并请求锁定对方占用资源，导致恶行循环
 - 当事务尝试以不同的顺序锁定资源时，可能产生死锁，多个事务同时锁定一个资源也可能产生死锁
 - 锁的行为和顺序和存储引擎有关，死锁双重原因：真正的数据冲突，存储引擎的实现方式
 检测死锁：数据库系统实现各种死锁检测和死锁超时的机制，InnoDB检测到死锁的循环依赖并立即返回一个错误
 死锁恢复：死锁发生后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB处理死锁方式，将持有最少行级排他锁的事务回滚
 外部锁的死锁检测：涉及外部锁，或涉及表锁情况，这需要通过设置锁等待超时参数`innodb_lock_wait_timeout`解决
 死锁影响性能：不会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务，在高并发系统，线程等待同一个锁时，死锁检测会变慢，`禁用死锁检测(innodb_deadlock_detect)`会有效，此时可依赖`innodb_lock_wait_timeout`事务回滚
 - MyISAM避免死锁
 在自动加锁情况，MyISAM总是一次获得SQL语句所需要的全部锁，所以MyISAM表不会出现死锁
 - InnoDB避免死锁
   - 为了在单个表执行多个并发写入操作时避免死锁，可以在事务开始时通过预期修改的灭个元祖(行)使用`SELECT FOR UPDATE`
   - 在事务中，如果要更新记录，应该申请足够级别锁，即排他锁，而不应先申请共享锁，更新时再申请排他锁，其他用户在申请排他锁，其他事务已经获得相同记录的共享锁，从而造成所冲突，甚至死锁
   - 如果事务需要修改或锁定多个表，则应再每个事务中以相同的顺序使用加锁语句，在应用中，如果不同程序会并发存取多个表，尽量按约定相同顺序访问表，大大降低产生死锁机会
   - 通过`SELECT LOCK IN SHARE MODE`获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则可能造成死锁
 如果出现死锁，可用`show engine innodb status;`命令确定最后一个死锁产生原因，分析死锁产生原因和改进措施

#### Mysql调优
##### 影响mysql的性能因素
 - 业务需求对Mysql的影响(合适合度)
 - 存储定位对Mysql的影响
   - 不适合放进Mysql的数据
     - 二进制多媒体数据
     - 流水队列数据
     - 超大文本数据
   - 需要放进缓存的数据
     - 系统配置及规则数据
     - 活跃用户基本信息数据
     - 活跃用户个性化定制信息数据
     - 准实时的统计信息数据
     - 其他访问频繁但变更较少的数据
 - Schema设计对系统的性能影响
   - 尽量减少对数据库的访问请求
   - 尽量减少无用数据的查询请求
##### 性能分析
 - Mysql中有专门负责优化SELECT语句的优化器模块，主要功能：通过计算分析收集到的统计信息，为客户端请求的Query提供最优计划
 - 当客户端向Mysql请求Query，命令解析器模块完成请求分类，区别出时SELECT并转发给`Mysql Query Optimizer`时，会对整条Query进行优化，处理掉表达式预算，查询条件简化和转换，分析Query中的Hint信息(如有)，确定并得出最后的执行计划
##### Mysql常见瓶颈
 - CPU：CPU再饱和的时候一般发生再数据装入内存或从磁盘上读取的时候
 - IO：磁盘IO瓶颈发生在装入数据远大于内存容量的时候
 - 服务器硬件的性能瓶颈：top free iostat vmstat查看系统性能状态
##### 性能下降SQL慢执行时间长等待时间长原因分析
 - 查询语句
 - 索引失效(单值、复合)
 - 关联查询太多join(设计缺陷导致的需求)
 - 服务器调优及参数设置(缓冲、线程数)
##### Mysql常见性能分析手段
 通常对数据库进行分析，常见分析：慢查询日志、EXPLAIN分析、profiling分析、show命令查询。通过定位分析性能
##### 性能瓶颈定位
 `Mysql> show status`   状态信息
 `Mysql> show variables`  系统信息
 `Mysql> show innodb status`  InnoDB存储引擎状态
 `Mysql> show processlist`  当前SQL执行，包括执行状态，是否锁表等
 `Shell> mysqladmin variables -u username -p password`  显示系统变量
 `Shell> mysqladmin extended-status -u username -p password`  显示状态信息
##### Explain
 Mysql如何处理SQL语句，分析查询语句或是表结构性能瓶颈
 - 表的读取顺序
 - 数据读取操作的操作系统
 - 哪些索引可以使用
 - 哪些索引实际被使用
 - 表之间的引用
 - 每张表有多少行被优化器查询
 字段解释
 - id (select 查询的序列号，包括一组数字，表示查询中执行select子句或操作表的顺序)
   - id相同，执行顺序从上往下
   - id全不同，如果是子查询，id序号会递增，id越大优先级越高
   - id部分相同，顺序按照数字越大，从上往下执行
 - select_type (查询类型，区别普通查询，联合查询，子查询等复杂查询)
   - SIMPLE：简单select查询，不包含子查询或UNION
   - PRIMARY：查询包括任何复杂的字部份，最外层查询被标记为PRIMARY
   - SUBQUERY：在select或where列表中包括子查询
   - DERIVED：在from列表中包含子查询，Mysql会递归子查询，结果放在临时表
   - UNION：若第二个select出现UNION之后，或UNION包含在from子句，外层select为DERIVED
   - UNION RESULT：从UNION表获取结果的select
 - table：表名
 - type (显示查询类型，最好依次排序system>const>eq_ref>ref>fulltext>ref_or_null>index_merge>unique_subquer>index_subquery>range>index>all)
   - system：表只有一行数据，const是类型特征
   - const：表示通过索引一次就找到
   - eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条数据与之匹配
   - ref：非唯一性索引，范围匹配某个单独值的所有行，本质索引访问
   - range：只检索给定范围的行
   - index：full index scan，index区别于all只遍历索引树，通常比all快，index从索引读取，all从硬盘读取
   - all：full table scan 遍历全表找到匹配行
   一般来说，的保证查询至少达到range级别，最好到达ref
 - possible_key (显示可能应用到的索引，一个或多个，查询涉及会被列出)
 - key
   - 实际使用的索引，为NULL，则没有使用索引
   - 查询中若使用覆盖索引，则该字段和查询select字段重叠，仅出现在key列表
 - key_len
   - 表示索引中使用的字节数，可通过该列计算查询中使用的索引长度，在不损失精确性的情况下，长度越短越好
   - key_len显示的值为索引的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的
 - ref (显示索引的哪一列被使用了，如果可能的话，是一个常数)
 - rows (根据表统计信息及索引选用情况，大致估算找到记录所需读取的行数)
 - Extra (包含不适合在其他列中显示但十分重要的额外信息)
   - using filesort：说明mysql会对数据使用一个外部索引排序，不是按照表内的索引顺序进行读取，mysql中无法利用索引完成的排序称为`文件排序`，常见于order by和group by中
   - using temporary：使用临时表保存中间结果，mysql在对查询结果排序时使用临时表，常见于排序order by和group by
   - using index：表示相应的select操作使用覆盖索引，避免访问了表的数据行，效率不错，如果出现using where，表面索引被用来执行索引键值的查找，否则索引被用来读取数据而非执行查找操作
   - using where：使用了where过滤
   - using join buffer：使用了连接缓存
   - impossible where：where子句的值总是false，不能用来获取任何元祖
   - select tables optimized away：在没有group by子句的情况下，基于索引优化操作或对MyISAM引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段及完成优化
   - distinct：优化distinct操作，再找到第一匹配的元祖后停止找同样值的操作
##### 慢查询日志
 记录Mysql中响应时间超过阈值的语句，具体指运行时间超过`long_query_time`值的SQL，则会被记录到慢查询
 - `long_query_time`默认值是10
 - 默认情况mysql没有开启慢查询日志
##### Show Profile 分析查询
 通过慢日志查询知道哪些SQL执行效率低下，通过explain我们可以得知SQL语句的具体执行情况，索引使用等
 - Show Profile是Mysql提供可以用来分析当前会话中语句执行的资源消耗情况
 - 默认关闭，并保存最近15次运行结果

#### 性能优化
##### 索引优化
 - 全值匹配
 - 最佳左前缀法则，联合索引(a,b,c)，可用索引：`a` `a,b` `a,b,c`
 - 不在索引列上做任何操作(计算，函数，`类型转换`)，会导致索引失效而转向全表扫描
 - 存储索引不能使用索引中范围条件右边的列
 - 尽量使用覆盖索引(只访问索引的查询`索引列和查询列一致`)，减少select
 - is null，is not null 也无法使用索引
 - like "xxxx%"是可以用到索引，like "%xxx"/"%xx%"则不行，like以通配符开头`%abc`索引失效变成全表扫描
 - 字符串不单加引号索引失效
 - 少用or，用它连接时索引会失效
 - <, <=, = >, >=, BETWEEN, IN可用到索引，<>, not in, !=则不行，会导致全表扫描
##### 一般性建议
 - 对于单键索引，尽量选择针对当前query过滤性更好的索引
 - 在选择组合索引时，当前query中过滤性最好的字段在索引字段顺序中，位置越前越好
 - 在选择组合索引时，尽量选择可以能够包含当前query中where字句中更多字段的索引
 - 尽可能通过分析统计信息和调整query的写法达到选择合适索引的目的
 - 少用Hint强制索引
##### 查询优化
 - 永远小表驱动大表 (小的数据集驱动大的数据集) AB表对应字段建立索引
   - 当B表的数据集小于A表的数据集时，用in优于exists`小表驱动大表用in`，反之exists优于in
 - order by关键字优化
   - order by子句，尽量使用index方式排序，避免使用FileSort方式排序
   - Mysql支持两种方式排序，FileSort和index，index效率高，它指Mysql扫描索引本身完成排序
   - Order by满足两种情况，会使用index排序：order by使用索引最左前列；使用where子句与order by子句条件列组合最左前列
   - 尽可能在索引列上完成排序操作，遵照索引键的最佳最前缀
   - 如果不在索引列上，filesort有两种算法，mysql就要启动`双路排序`和`单路排序`
     - 双路排序：Mysql4.1之前是使用双路排序，两次扫描磁盘
     - 单路排序：从磁盘读取查询所需要的列，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出，效果高
   - 优化策略
     - 增大`sort_buffer_size`参数设置
     - 增大`max_length_for_sort_data`参数设置
   - Group by关键字优化
     - group by实质实现排序后进行分组，遵照索引键最佳左前缀
     - 当无法使用索引列，增大`max_length_for_sort_data`参数设置，增大`sort_buffer_size`参数设置
     - where高于having，能写where限定条件就不要去用having
 - 数据类型优化
   - 更小更好：尽量选择使用正确存储数据的最小数据类型
   - 简单：简单的数据类型，利于排序
   - 尽量避免NULL：通常情况下最好指定列为NOT NULL

#### Mysql分区、分表、分库
##### Mysql分区
 创建的表对应一组存储文件，使用MyISAM存储引擎是一个`.MYI`和`.MYD`文件，使用InnoDB存储引擎是一个`.ibd`和`.frm(表结构)`
 当数据量较大时(一般千万条记录级别以上)，Mysql性能就会开始下降，需要将数据分散到多组存储文件，保证其单个文件的执行效率
 - 作用
   - 逻辑数据分割
   - 提高单一的写和读应用的速度
   - 提高区分范围读查询的速度
   - 分割数据能够有多个不同的物理文件路径
   - 高效保存历史数据
 - 如何实现
   - Mysql5.6以及之前版本
     `SHOW VARIABLES LIKE '%partition%'`
   - Mysql5.6
     `show plugins`
   - 分区类型及操作
     - RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区，mysql将会根据指定的拆分策略，把数据放在不同的表文件上，相当于在文件上，被拆分成了小块，对外给客户的感觉还是一张表，透明的。
     按照range来分，就是每个库一段连续的数据，这个时按比如时间范围来的，可以根据年月来存放数据，可能产生热点问题，大量流量打在最新的数据是。range来分，好处在于扩容的时候很简单
     - LIST分区：类似于按RANGE分区，每个分区必须明确定义，主要区别在于，LIST分区中每个分区的定义和选择时基于某列的值属于一个值列表，而RANGE分区是从属于一个连续区间值的集合
     - HASH分区：基于用户定义的表达式返回值来进行选择分区，该表达式使用将要插入到表中的这些行的列值进行计算，这个函数可以包含Mysql中有效的、产生非负整数值的任何表达式。hash分区，好处在于可以平均分配每个库的数据量和请求压力，坏处在于扩容比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算hash值重新分配到不同的库或表
     - KEY分区：类似于HASH分区，区别在于KEY分区只支持一列或多列，且Mysql服务器提供自身的哈希函数，必须有一列或多列包含整数值
   - 为什么更多选择分库分表来水平扩展
     - 分区表，分区键涉及不太灵活，如果不走分区键，很容易出现全表锁
     - 一旦数据并发量上来，如果在分区表实施关联，就时灾难
     - 自己分库分表，自己掌握业务场景访问模式，可控，分区表，不确定Mysql操作，不可控
   - 随着业务发展，业务复杂，模块多，总的数据量大，高并发读写操作超过单个数据库服务器处理能力怎么办
     - 这时出现`数据分片`，数据分片指按照某个维度将存放在单一数据库中的数据分散的存放至多个数据库或表中，数据分片的有效手段就就是对关系型数据库进行分库和分表
     区别于分区，分区一般都是放在单机里，用的比较多的是范围分区，方便归档，只不过分库分表需要代码实现，分区则是mysql内部实现，分库分表和分区并不冲突，可以结合使用
##### Mysql分表
 分表有两种分割方式，一种时垂直拆分，另一种水平拆分
 - 垂直拆分
   垂直分表，通常是按照业务功能使用的频次，把主要的、热门的字段放在一起作为主要表，然后把不常用的，按照各自业务属性进行聚集，拆分到不同的次要表中，主要表和次要表的关系一般都是一对一的
 - 水平拆分(数据分片)
   单表的容量不超过500W，否则建议水平拆分，是把一个表复制成同样的表结构的不同表，然后把数据按照一定的规则划分，分别存储到这些表中，从而保证单表的容量不会太大，提升性能，当然这些结构可以放在一个或多个数据库中
   水平分割的方法
   - 使用MD5哈希：对UID进行MD5加密，然后取前几位，然后可以将不同的UID哈希到不同的用户表(user_xxx)
   - 根据时间放入不同的表：user_202302, user_202303
   - 按热度拆分，高点击率词条生成各自的一张表，低点击率词条都放在大表，待词条热度上升，再把低热度表单独拆分为一张表
   - 根据ID的值放入对应的表，user_1-1000 user_1001_2000
##### Mysql分库
 为什么分库
  数据库集群环境都是多台slave，但是写入或者大数据，频繁写入操作对master性能影响比较大，这个时候，单库并不能解决大规模并发写入的问题
 什么是分库
  库里表太多，导致海量数据，系统性能下降，把原本存储于一个库的表拆分到多个库上，通常是将表按照功能模块，关系密切程度划分部署
 优点
 - 减少增量数据写入时的锁对查询的影响
 - 由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单词查询所需的检索行数表少，减少磁盘IO，时延变短
 但是无法解决单表数据量太大的问题
 分库分表后的难题
  分布式事务的问题，数据的完整性和一致性问题
  数据操作维度问题：用户、交易、订单各个不同维度，用户查询维度，产品数据分析维度的不同对比分析角度，跨库联合查询的问题，可能需要分别在各个节点上得到结果后在应用程序端进行合并，额外的数据管理负担，合并计算开发难度提升

#### Mysql主从复制
##### 复制的基本原理
 - slave会从master读取binlog来进行数据同步
 - 三个步骤
   - master将改变记录到二进制日志，这些记录过程叫做二进制日志事件，`binary log events`
   - slave将master的 `binary log events`拷贝到它的中继日志`relay log`
   - slave 重做中继日志中的事件，将改变应用到自己的数据库中，Mysql复制时异步且串行化的
##### 复制的基本原则
 - 每个slave只有一个master
 - 每个slave只有一个唯一的服务器ID
 - 每个master可以有多个slave
##### 复制的最大问题
 - 延时

#### Mysql其他问题
##### 说一说三个范式
 - 第一范式(1NF)：数据库表中的字段都是单一属性的，不可再分，这个单一属性由基本类型构成：整型、实数、字符型
 - 第二范式(2NF)：数据库表中不存在非关键字段对任一候选关键字段的不分寒暑依赖，也及所有的非关键字段完全依赖任意候选关键字
 - 第三范式(3NF)：在第二范式的基础上，数据表中如果不存在非关键字段对任意候选关键字段的传递函数依赖则符合第三范式，所谓传递函数依赖，指的是如果`A->B->C`的决定关系，则`C`传递函数依赖于`A`，依次满足第三范式的数据库应该不存在如下依赖关系
 `关键字段->非关键字段x->非关键字段y`
##### 百万级或以上的数据如何删除
 关于索引：由于索引需要额外的维护成本，因为索引文件是单独存放的文件，所以我们对数据增改删都会产生额外的索引文件操作，这些操作需要额外的IO，会降低增改删的执行效率，所以在删除百万级数据时，删除数据的速度和创建索引数量成正比
 - 所以删除百万级数据之前先删除索引
 - 然后删除无用数据
 - 删除完后重新创建索引
 - 与直接删除比快速很多，万一删除终端就会回滚